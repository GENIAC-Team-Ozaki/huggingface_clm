{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mistral　事前学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fuyu-quant/huggingface_deepspeed/blob/main/example/pretraining_mistral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLYQRk1ZWiSG",
        "outputId": "450f650c-6fb9-4175-c008-3abdb3b0695e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'clm_deepspeed'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 41 (delta 18), reused 27 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (41/41), 16.15 KiB | 2.69 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/fuyu-quant/clm_deepspeed.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uv57zD9iXKCJ",
        "outputId": "cd5f9ff9-1797-400f-9cfc-0f5662ac0d90"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd clm_deepspeed\n",
        "!pip install flash-attn==2.3.4 --no-build-isolation\n",
        "!pip install -r requirements.txt\n",
        "%cd ../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RstT7IfgXayg"
      },
      "source": [
        "### トークナイザーの用意"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjHNE4bYXbQd",
        "outputId": "b9c9c2b6-96dc-4bb8-fbc4-c1d157d84ac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'japanese-mistral-300m-base'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 34 (delta 4), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (34/34), 948.36 KiB | 2.84 MiB/s, done.\n",
            "Filtering content: 100% (12/12), 2.65 GiB | 55.70 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# todo 学習済トークナイザーをダウンロード\n",
        "!git clone https://huggingface.co/ce-lery/japanese-mistral-300m-base.git\n",
        "# spm-wiki-cc100-for-spm-bytefallbackという名称で保存\n",
        "!mv japanese-mistral-300m-base spm_tokenizer_neologdn_bytefallback_nofast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31vXeZvTcjf1"
      },
      "source": [
        "### 事前学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r5WWY60cseX",
        "outputId": "b322f98c-23e7-454a-fd8e-3e16209fe1a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2024-04-08 15:37:50,265] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-04-08 15:37:56,808] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2024-04-08 15:37:56,809] [INFO] [runner.py:570:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --no_local_rank --enable_each_rank_log=None clm_deepspeed/src/mistral/run_clm.py clm_deepspeed/config/pretraining2.json --deepspeed --deepspeed_config clm_deepspeed/config/ds_config_zero3.json\n",
            "[2024-04-08 15:37:59,314] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-04-08 15:38:01,613] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2024-04-08 15:38:01,613] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-04-08 15:38:01,613] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2024-04-08 15:38:01,613] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2024-04-08 15:38:01,613] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2024-04-08 15:38:01,613] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2024-04-08 15:38:01,613] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-04-08 15:38:01,614] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2024-04-08 15:38:01,614] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2024-04-08 15:38:01,614] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2024-04-08 15:38:01,614] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2024-04-08 15:38:01,614] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "2024-04-08 15:38:06.894707: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-08 15:38:06.894764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-08 15:38:07.015772: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-08 15:38:09.442062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12020, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
            "The speedups for torchdynamo mostly come wih GPU Ampere or higher and which is not detected here.\n",
            "04/08/2024 15:38:13 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\n",
            "04/08/2024 15:38:13 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.95,\n",
            "adam_epsilon=0.0001,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=8,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=100,\n",
            "evaluation_strategy=steps,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=256,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0006,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=checkpoints-mistral-300M-FA2/logs,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=cosine,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=100,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_bnb_8bit,\n",
            "optim_args=None,\n",
            "output_dir=checkpoints-mistral-300M-FA2,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=True,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=checkpoints-mistral-300M-FA2,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=False,\n",
            "tf32=None,\n",
            "torch_compile=True,\n",
            "torch_compile_backend=inductor,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=1000,\n",
            "weight_decay=0.1,\n",
            ")\n",
            "https://huggingface.co/datasets/wikipedia/resolve/main/wikipedia.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/f951474db3ed06e138222f595a23ab156c2ee71eae9790f97e9250990bdad5c8.9b061d9a7f561446706bea92d84e277bc736a9230e138d81229f193f33328038.py.incomplete\n",
            "04/08/2024 15:38:13 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/wikipedia/resolve/main/wikipedia.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/f951474db3ed06e138222f595a23ab156c2ee71eae9790f97e9250990bdad5c8.9b061d9a7f561446706bea92d84e277bc736a9230e138d81229f193f33328038.py.incomplete\n",
            "Downloading builder script: 100% 36.7k/36.7k [00:00<00:00, 24.3MB/s]\n",
            "storing https://huggingface.co/datasets/wikipedia/resolve/main/wikipedia.py in cache at /root/.cache/huggingface/datasets/downloads/f951474db3ed06e138222f595a23ab156c2ee71eae9790f97e9250990bdad5c8.9b061d9a7f561446706bea92d84e277bc736a9230e138d81229f193f33328038.py\n",
            "04/08/2024 15:38:14 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/wikipedia/resolve/main/wikipedia.py in cache at /root/.cache/huggingface/datasets/downloads/f951474db3ed06e138222f595a23ab156c2ee71eae9790f97e9250990bdad5c8.9b061d9a7f561446706bea92d84e277bc736a9230e138d81229f193f33328038.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/f951474db3ed06e138222f595a23ab156c2ee71eae9790f97e9250990bdad5c8.9b061d9a7f561446706bea92d84e277bc736a9230e138d81229f193f33328038.py\n",
            "04/08/2024 15:38:14 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/f951474db3ed06e138222f595a23ab156c2ee71eae9790f97e9250990bdad5c8.9b061d9a7f561446706bea92d84e277bc736a9230e138d81229f193f33328038.py\n",
            "https://huggingface.co/datasets/wikipedia/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/2c5427c6ed71bad01391fe13fe241f6cfc93b1ff3d1c29524e0a0f4b614636fb.4a8d03211d793b2c84ee1f12b75928c890a9ddc80096bc960d00f4efb8dd1a70.incomplete\n",
            "04/08/2024 15:38:14 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/wikipedia/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/2c5427c6ed71bad01391fe13fe241f6cfc93b1ff3d1c29524e0a0f4b614636fb.4a8d03211d793b2c84ee1f12b75928c890a9ddc80096bc960d00f4efb8dd1a70.incomplete\n",
            "Downloading readme: 100% 16.0k/16.0k [00:00<00:00, 11.9MB/s]\n",
            "storing https://huggingface.co/datasets/wikipedia/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/2c5427c6ed71bad01391fe13fe241f6cfc93b1ff3d1c29524e0a0f4b614636fb.4a8d03211d793b2c84ee1f12b75928c890a9ddc80096bc960d00f4efb8dd1a70\n",
            "04/08/2024 15:38:14 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/wikipedia/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/2c5427c6ed71bad01391fe13fe241f6cfc93b1ff3d1c29524e0a0f4b614636fb.4a8d03211d793b2c84ee1f12b75928c890a9ddc80096bc960d00f4efb8dd1a70\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/2c5427c6ed71bad01391fe13fe241f6cfc93b1ff3d1c29524e0a0f4b614636fb.4a8d03211d793b2c84ee1f12b75928c890a9ddc80096bc960d00f4efb8dd1a70\n",
            "04/08/2024 15:38:14 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/2c5427c6ed71bad01391fe13fe241f6cfc93b1ff3d1c29524e0a0f4b614636fb.4a8d03211d793b2c84ee1f12b75928c890a9ddc80096bc960d00f4efb8dd1a70\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikipedia/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001\n",
            "04/08/2024 15:38:14 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikipedia/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001\n",
            "Generating dataset wikipedia (/root/.cache/huggingface/datasets/wikipedia/20220301.ja/2.0.0/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001)\n",
            "04/08/2024 15:38:14 - INFO - datasets.builder - Generating dataset wikipedia (/root/.cache/huggingface/datasets/wikipedia/20220301.ja/2.0.0/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001)\n",
            "Downloading and preparing dataset wikipedia/20220301.ja to /root/.cache/huggingface/datasets/wikipedia/20220301.ja/2.0.0/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001...\n",
            "04/08/2024 15:38:14 - INFO - datasets.builder - Downloading and preparing dataset wikipedia/20220301.ja to /root/.cache/huggingface/datasets/wikipedia/20220301.ja/2.0.0/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001...\n",
            "Dataset not on Hf google storage. Downloading and preparing it from source\n",
            "04/08/2024 15:38:15 - INFO - datasets.builder - Dataset not on Hf google storage. Downloading and preparing it from source\n",
            "Downloading data files:   0% 0/1 [00:00<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"/content/clm_deepspeed/src/mistral/run_clm.py\", line 687, in <module>\n",
            "    main()\n",
            "  File \"/content/clm_deepspeed/src/mistral/run_clm.py\", line 329, in main\n",
            "    raw_datasets = load_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2153, in load_dataset\n",
            "    builder_instance.download_and_prepare(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 954, in download_and_prepare\n",
            "    self._download_and_prepare(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 1027, in _download_and_prepare\n",
            "    split_generators = self._split_generators(dl_manager, **split_generators_kwargs)\n",
            "  File \"/root/.cache/huggingface/modules/datasets_modules/datasets/wikipedia/d41137e149b2ea90eead07e7e3f805119a8c22dd1d5b61651af8e3e3ee736001/wikipedia.py\", line 973, in _split_generators\n",
            "    downloaded_files = dl_manager.download_and_extract({\"info\": info_url})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\", line 565, in download_and_extract\n",
            "    return self.extract(self.download(url_or_urls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\", line 428, in download\n",
            "    downloaded_path_or_paths = map_nested(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\", line 464, in map_nested\n",
            "    mapped = [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\", line 465, in <listcomp>\n",
            "    _single_map_nested((function, obj, types, None, True, None))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\", line 367, in _single_map_nested\n",
            "    return function(data_struct)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\", line 454, in _download\n",
            "    return cached_path(url_or_filename, download_config=download_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py\", line 182, in cached_path\n",
            "    output_path = get_from_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py\", line 596, in get_from_cache\n",
            "    raise FileNotFoundError(f\"Couldn't find file at {url}\")\n",
            "FileNotFoundError: Couldn't find file at https://dumps.wikimedia.org/jawiki/20220301/dumpstatus.json\n",
            "Downloading data files:   0% 0/1 [00:00<?, ?it/s]\n",
            "[2024-04-08 15:38:18,631] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 4292\n",
            "[2024-04-08 15:38:18,632] [ERROR] [launch.py:321:sigkill_handler] ['/usr/bin/python3', '-u', 'clm_deepspeed/src/mistral/run_clm.py', 'clm_deepspeed/config/pretraining2.json', '--deepspeed', '--deepspeed_config', 'clm_deepspeed/config/ds_config_zero3.json'] exits with return code = 1\n"
          ]
        }
      ],
      "source": [
        "!deepspeed --no_local_rank clm_deepspeed/src/mistral/run_clm.py clm_deepspeed/config/pretraining2.json --deepspeed --deepspeed_config clm_deepspeed/config/ds_config_zero3.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE_uQs9DuZ9f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyP508nCqh73jXakk1HqWyIg",
      "gpuType": "V100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
